(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{138:function(e,t,a){"use strict";a.d(t,"a",(function(){return p})),a.d(t,"b",(function(){return h}));var r=a(0),b=a.n(r);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function c(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?c(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):c(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,r,b=function(e,t){if(null==e)return{};var a,r,b={},n=Object.keys(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||(b[a]=e[a]);return b}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(b[a]=e[a])}return b}var s=b.a.createContext({}),i=function(e){var t=b.a.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=i(e.components);return b.a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return b.a.createElement(b.a.Fragment,{},t)}},d=b.a.forwardRef((function(e,t){var a=e.components,r=e.mdxType,n=e.originalType,c=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),p=i(a),d=r,h=p["".concat(c,".").concat(d)]||p[d]||u[d]||n;return a?b.a.createElement(h,o(o({ref:t},s),{},{components:a})):b.a.createElement(h,o({ref:t},s))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var n=a.length,c=new Array(n);c[0]=d;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o.mdxType="string"==typeof e?e:r,c[1]=o;for(var s=2;s<n;s++)c[s]=a[s];return b.a.createElement.apply(null,c)}return b.a.createElement.apply(null,a)}d.displayName="MDXCreateElement"},86:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return c})),a.d(t,"metadata",(function(){return o})),a.d(t,"toc",(function(){return l})),a.d(t,"default",(function(){return i}));var r=a(3),b=a(7),n=(a(0),a(138)),c={id:"services-utilities",title:"Utilities"},o={unversionedId:"services-utilities",id:"services-utilities",isDocsHomePage:!1,title:"Utilities",description:"We list here the services available for deployment within a Data2Services project.",source:"@site/docs/services-utilities.md",slug:"/services-utilities",permalink:"/docs/services-utilities",editUrl:"https://github.com/MaastrichtU-IDS/d2s-docs/edit/master/website/docs/services-utilities.md",version:"current",lastUpdatedBy:"Vincent Emonet",lastUpdatedAt:1611146072,sidebar:"docs",previous:{title:"Interfaces",permalink:"/docs/services-interfaces"},next:{title:"Add a new dataset",permalink:"/docs/d2s-new-dataset"}},l=[{value:"Integrated services",id:"integrated-services",children:[{value:"Jupyter Notebooks",id:"jupyter-notebooks",children:[]},{value:"Spark Notebooks",id:"spark-notebooks",children:[]},{value:"Docket multiomics data provider",id:"docket-multiomics-data-provider",children:[]},{value:"RMLStreamer",id:"rmlstreamer",children:[]},{value:"Nanobench",id:"nanobench",children:[]},{value:"FAIR Data Point",id:"fair-data-point",children:[]},{value:"Apache Drill",id:"apache-drill",children:[]},{value:"Postgres",id:"postgres",children:[]},{value:"LIMES interlinking",id:"limes-interlinking",children:[]}]},{value:"Executables and modules",id:"executables-and-modules",children:[{value:"d2s-sparql-operations",id:"d2s-sparql-operations",children:[]},{value:"Comunica",id:"comunica",children:[]},{value:"RdfUpload",id:"rdfupload",children:[]},{value:"AutoR2RML",id:"autor2rml",children:[]},{value:"R2RML",id:"r2rml",children:[]},{value:"xml2rdf",id:"xml2rdf",children:[]},{value:"json2xml",id:"json2xml",children:[]},{value:"PyShEx",id:"pyshex",children:[]},{value:"rdf2hdt",id:"rdf2hdt",children:[]},{value:"Jena riot validate RDF",id:"jena-riot-validate-rdf",children:[]},{value:"Raptor rdf2rdf",id:"raptor-rdf2rdf",children:[]},{value:"rdf2neo",id:"rdf2neo",children:[]},{value:"d2s-bash-exec",id:"d2s-bash-exec",children:[]}]},{value:"Additional services",id:"additional-services",children:[{value:"BridgeDb",id:"bridgedb",children:[]},{value:"RDF tools to try",id:"rdf-tools-to-try",children:[]}]}],s={toc:l};function i(e){var t=e.components,a=Object(b.a)(e,["components"]);return Object(n.b)("wrapper",Object(r.a)({},s,a,{components:t,mdxType:"MDXLayout"}),Object(n.b)("p",null,"We list here the services available for deployment within a Data2Services project."),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"The ",Object(n.b)("inlineCode",{parentName:"p"},"d2s start")," command is provided when available. A ",Object(n.b)("inlineCode",{parentName:"p"},"docker run")," command is provided for every module.")),Object(n.b)("p",null,"Feel free to propose new services using ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/d2s-docs/pulls"}),"pull requests")," or creating a ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/d2s-docs/issues"}),"new issue"),"."),Object(n.b)("p",null,"Each service is run using ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://docs.docker.com/install/"}),"Docker"),". They have been configured to be deployed on a common network, sharing volumes in ",Object(n.b)("inlineCode",{parentName:"p"},"workspace/"),". Services configuration can be changed in the docker-compose.yml file or using deployments."),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"See also the list of tools to work with knowledge graphs published by STI Innsbruck at ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://stiinnsbruck.github.io/kgs"}),"stiinnsbruck.github.io/kgs"))),Object(n.b)("hr",null),Object(n.b)("h2",{id:"integrated-services"},"Integrated services"),Object(n.b)("h3",{id:"jupyter-notebooks"},"Jupyter Notebooks"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/amalic/Jupyterlab"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/amalic/Jupyterlab?label=GitHub&style=social",alt:"JupyterLab"})))),Object(n.b)("p",null,"Deploy ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/amalic/Jupyterlab"}),"JupyterLab")," to use Notebooks to build or consume your RDF Knowledge Graph. Query your knowledge graph through its SPARQL endpoint, or the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"/docs/services-interfaces#d2s-api"}),"HTTP OpenAPI")," using Python, or R. "),Object(n.b)("p",null,"The proposed deployment comes with example queries to perform data processing using tools such as ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/monarch-initiative/dipper"}),"Dipper"),", ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://docs.biothings.io/en/latest/"}),"BioThings"),", or various RDF and Data Science libraries. Example are also provided to start querying data from the produced RDF Knowledge Graph. See the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/vemonet/translator-sparql-notebook"}),"GitHub repository"),"."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),'d2s start notebook\n\ndocker run --rm -it -p 8888:8888 \\\n  -v $(pwd)/workspace:/notebooks/workspace \\\n  -v $(pwd)/datasets:/notebooks/datasets \\\n  -e PASSWORD="<your_secret>" \\\n  -e GIT_URL="https://github.com/vemonet/translator-sparql-notebook" \\\n  umids/jupyterlab:latest\n')),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Access on http://localhost:8888")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Change the Notebook password in the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/d2s-core"}),"docker-compose.yml file"),". Different passwords can be defined for different deployments.")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"spark-notebooks"},"Spark Notebooks"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/vemonet/jupyterlab-spark"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/vemonet/jupyterlab-spark?label=GitHub&style=social",alt:"Spark JupyterLab"})))),Object(n.b)("p",null,"Deploy ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/vemonet/jupyterlab-spark"}),"JupyterLab")," to use Notebooks to process data using ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://spark.apache.org/"}),"Apache Spark"),". See the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/vemonet/jupyterlab-spark"}),"GitHub repository")," for more details about the build."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"d2s start spark-notebook\n\ndocker run --rm -it -p 8889:8888 \\\n  -v $(pwd)/workspace:/home/jovyan/work/workspace\n  -v $(pwd)/datasets:/home/jovyan/work/datasets\n  -e JUPYTER_ENABLE_LAB=yes \\\n  umids/jupyterlab-spark \\\n  start-notebook.sh  --NotebookApp.password='sha1:9316432938f9:93985dffbb854d31308dfe0602a51db947fb7d80'\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Access on http://localhost:8889")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Default password is ",Object(n.b)("inlineCode",{parentName:"p"},"password"))),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Generate a hash for your password in a Notebook by running:"),Object(n.b)("pre",{parentName:"blockquote"},Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"from notebook.auth import passwd\npasswd()\n"))),Object(n.b)("hr",null),Object(n.b)("h3",{id:"docket-multiomics-data-provider"},"Docket multiomics data provider"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/PriceLab/DOCKET"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/PriceLab/DOCKET?label=GitHub&style=social",alt:"DOCKET"})))),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/PriceLab/DOCKET"}),"DOCKET")," is a Dataset Overview, Comparison and Knowledge Extraction Tool built as Multiomics provider for the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://ncats.nih.gov/translator"}),"NCATS Translator project"),"."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"d2s start docket\n\ndocker run -d --rm --name docket \\\n  -p 8002:8888 -e PYTHONPATH=/app \\\n  -v $(pwd)/workspace/docket:/data \\\n  umids/docket:latest\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Access Notebooks at http://localhost:8002")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"rmlstreamer"},"RMLStreamer"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/RMLio/rmlmapper-java"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/RMLio/rmlmapper-java?label=GitHub&style=social",alt:"RMLMapper"})))),Object(n.b)("p",null,"Use the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://rml.io/"}),"RDF Mapping Language (RML)")," to map your structured data (CSV, TSV, SQL, XML, JSON, YAML) to RDF. The ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/RMLio/RMLStreamer/"}),"RMLStreamer")," is a scalable implementation of RML in development."),Object(n.b)("p",null,"The ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://rml.io/specs/rml/"}),"RML mappings")," needs to be defined as in a file with the extension ",Object(n.b)("inlineCode",{parentName:"p"},".rml.ttl"),", in the mapping folder of the dataset to transform, e.g. ",Object(n.b)("inlineCode",{parentName:"p"},"datasets/dataset_id/mapping/associations-mapping.rml.ttl")),Object(n.b)("p",null,"Start the required services:"),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"d2s start rmlstreamer rmltask\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Access at http://localhost:8078 to see running jobs.")),Object(n.b)("p",null,"Run the RMLStreamer:"),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"d2s rml cohd\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Output goes to ",Object(n.b)("inlineCode",{parentName:"p"},"workspace/import/associations-mapping_rml_ttl-cohd.nt"))),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"}," See the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/RMLio/RMLStreamer/blob/master/docker/README.md"}),"original RMLStreamer documentation")," to deploy using Docker.")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"nanobench"},"Nanobench"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/peta-pico/nanobench"}),"Nanobench")," is a web UI to publish ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://nanopub.org/"}),"Nanopublications"),"."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"d2s start nanobench\n\ndocker run -d --rm --name nanobench -p 37373:37373 \\\n  -v $(pwd)/workspace/.nanopub:/root/.nanopub \\\n  -e NANOBENCH_API_INSTANCES=http://grlc.np.dumontierlab.com/api/local/local/ http://grlc.nanopubs.lod.labs.vu.nl/api/local/local/ http://130.60.24.146:7881/api/local/local/ \\\n  nanopub/nanobench\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Access on http://localhost:37373")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Follow the web UI instructions to get started and publish nanopublications.")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"You can easily create and publish new templates following instructions at the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/nanobench-templates"}),"nanobench-templates repository"),".")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"fair-data-point"},"FAIR Data Point"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/FAIRDataTeam/FAIRDataPoint"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/FAIRDataTeam/FAIRDataPoint?label=GitHub&style=social",alt:null})))),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/FAIRDataTeam/FAIRDataPoint"}),"FAIR Data Point (FDP)")," is a REST API for creating, storing, and serving FAIR metadata. This FDP implementation also presents a Web-based graphical user interface (GUI). The metadata contents are generated ",Object(n.b)("inlineCode",{parentName:"p"},"semi-automatically")," according to the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/FAIRDataTeam/FAIRDataPoint-Spec"}),"FAIR Data Point software specification")," document."),Object(n.b)("p",null,"More information about FDP and how to deploy can be found at ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://fairdatapoint.readthedocs.io/"}),"FDP Deployment Documentation"),"."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"d2s start fairdatapoint\n")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"apache-drill"},"Apache Drill"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/apache-drill"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/MaastrichtU-IDS/apache-drill?label=GitHub&style=social",alt:null})))),Object(n.b)("p",null,"Exposes tabular text files (CSV, TSV, PSV) as SQL, and enables queries on large datasets. Used by ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/amalic/AutoR2RML"}),"AutoR2RML")," and ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/amalic/r2rml"}),"R2RML")," to convert tabular files to a generic RDF representation."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"d2s start drill\n\ndocker run -dit --rm -p 8047:8047 -p 31011:31010 \\\n    --name drill -v $(pwd)/workspace/input:/data:ro umids/apache-drill:latest\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Access at ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://localhost:8047/"}),"http://localhost:8047/"),".")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"See on ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://hub.docker.com/r/umids/apache-drill"}),"DockerHub"),".")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"postgres"},"Postgres"),Object(n.b)("p",null,"Popular SQL database."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"d2s start postgres\n\ndocker run --name postgres -p 5432:5432 -e POSTGRES_PASSWORD=pwd -d -v $(pwd)/workspace/postgres:/data postgres\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Password is ",Object(n.b)("inlineCode",{parentName:"p"},"pwd"))),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"See the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"/docs/guide-postgres"}),"Postgres guide")," for more details.")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"limes-interlinking"},"LIMES interlinking"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/dice-group/LIMES"}),"LIMES")," is a tool developed by DICE group to perform interlinking between RDF entities using ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://dice-group.github.io/LIMES/#/user_manual/configuration_file/defining_link_specifications?id=implemented-measures"}),"various metrics"),": Cosine, ExactMatch, Levenshtein... "),Object(n.b)("p",null,"Start the LIMES server:"),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-bash"}),"d2s start limes-server\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Access at http://localhost:8090")),Object(n.b)("p",null,"See the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://dice-group.github.io/LIMES/#/user_manual/running_limes?id=using-the-cli-server"}),"official documentation to use the deployed REST API")," to submit LIMES jobs."),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://www.postman.com/product/api-client"}),"Postman")," can be used to perform HTTP POST queries on the API.")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"A newly released ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://limes.aksw.org/"}),"public Web UI")," can also be tried in the browser.")),Object(n.b)("hr",null),Object(n.b)("h2",{id:"executables-and-modules"},"Executables and modules"),Object(n.b)("h3",{id:"d2s-sparql-operations"},"d2s-sparql-operations"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/d2s-sparql-operations"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/MaastrichtU-IDS/d2s-sparql-operations?label=GitHub&style=social",alt:"GitHub"})))),Object(n.b)("p",null,"Execute ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://www.w3.org/TR/sparql11-query/"}),"SPARQL")," queries from string, URL or multiple files using ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://rdf4j.org/"}),"RDF4J"),". Available on ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://hub.docker.com/r/umids/d2s-sparql-operations"}),"DockerHub"),"."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),'docker run -it --rm umids/d2s-sparql-operations:latest -op select \\\n  -sp "select distinct ?Concept where {[] a ?Concept} LIMIT 10" \\\n  -ep "http://dbpedia.org/sparql"\n  \n# Provide the URL to a GitHub folder to execute all .rq files in it\ndocker run -it --rm umids/d2s-sparql-operations \\\n  -ep "https://graphdb.dumontierlab.com/repositories/public/statements" \\\n  -op update -un my_username -pw my_password \\\n  -f "https://github.com/MaastrichtU-IDS/d2s-sparql-operations/tree/master/src/main/resources/insert-examples"\n')),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"See ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://maastrichtu-ids.github.io/d2s-sparql-operations/"}),"documentation"),".")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"comunica"},"Comunica"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/comunica/comunica"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/comunica/comunica?label=GitHub&style=social",alt:"GitHub"})))),Object(n.b)("p",null,"Framework to perform ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://www.w3.org/TR/sparql11-federated-query/"}),"federated queries")," over a lot of different stores (triplestores, ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://linkeddatafragments.org/in-depth/"}),"TPF"),", ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://www.rdfhdt.org/"}),"HDT"),")."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),'docker run -it comunica/actor-init-sparql \\\n    http://fragments.dbpedia.org/2015-10/en \\\n    "CONSTRUCT WHERE { ?s ?p ?o } LIMIT 100"\n')),Object(n.b)("hr",null),Object(n.b)("h3",{id:"rdfupload"},"RdfUpload"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/RdfUpload"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/MaastrichtU-IDS/RdfUpload?label=GitHub&style=social",alt:null})))),Object(n.b)("p",null,"Upload RDF files to a triplestore."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),'docker run -it --rm --link graphdb:graphdb -v $(pwd)/workspace/import:/data \\\n    umids/rdf-upload:latest -m "HTTP" -if "/data" \\\n    -url "http://graphdb:7200" -rep "test" \\\n    -un "username" -pw "password"\n')),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"See on ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://hub.docker.com/r/umids/rdf-upload"}),"DockerHub"),".")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"autor2rml"},"AutoR2RML"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/AutoR2RML"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/MaastrichtU-IDS/AutoR2RML?label=GitHub&style=social",alt:null})))),Object(n.b)("p",null,"Automatically generate ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://www.w3.org/TR/r2rml/"}),"R2RML")," files from Relational databases (SQL, Postgresql)."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),'docker run -it --rm --link drill:drill --link postgres:postgres -v $(pwd)/workspace/input:/data \\\n    umids/autor2rml:latest -j "jdbc:drill:drillbit=drill:31010" -r \\\n    -o "/data/d2s-workspace/mapping.trig" \\\n    -d "/data/d2s-workspace" \\\n    -u "postgres" -p "pwd" \\\n    -b "https://w3id.org/d2s/" \\\n    -g "https://w3id.org/d2s/graph"\n')),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Can be combined with ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/amalic/apache-drill"}),"Apache Drill")," to process tabular files")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"See on ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://hub.docker.com/r/umids/autor2rml"}),"DockerHub"),".")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"r2rml"},"R2RML"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/r2rml"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/MaastrichtU-IDS/r2rml?label=GitHub&style=social",alt:null})))),Object(n.b)("p",null,"Convert Relational Databases to RDF using the ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://www.w3.org/TR/r2rml/"}),"R2RML")," mapping language."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"docker run -it --rm --net d2s-core_network \\\n  -v $(pwd)/workspace/input:/data \\\n  umids/r2rml:latest \\ \n  --connectionURL jdbc:drill:drillbit=drill:31010 \\\n  --mappingFile /data/mapping.trig \\\n  --outputFile /data/rdf_output.nq \\\n  --format NQUADS\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Shared on ",Object(n.b)("inlineCode",{parentName:"p"},"/data/d2s"))),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Can be combined with ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/amalic/apache-drill"}),"Apache Drill")," to process tabular files.")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"See on ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://hub.docker.com/r/umids/r2rml"}),"DockerHub"),".")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"xml2rdf"},"xml2rdf"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/xml2rdf"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/MaastrichtU-IDS/xml2rdf?label=GitHub&style=social",alt:null})))),Object(n.b)("p",null,"Streams XML to a ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/xml2rdf#rdf-model"}),"generic RDF")," representing the structure of the file. "),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),'docker run --rm -it -v $(pwd)/workspace/input:/data umids/xml2rdf:latest  \\\n    -i "/data/d2s-workspace/file.xml.gz" \\\n    -o "/data/d2s-workspace/file.nq.gz" \\\n    -g "https://w3id.org/d2s/graph"\n')),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"See on ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://hub.docker.com/r/umids/xml2rdf"}),"DockerHub"),".")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"json2xml"},"json2xml"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/lukas-krecan/json2xml"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/lukas-krecan/json2xml?label=GitHub&style=social",alt:null})))),Object(n.b)("p",null,"Convert JSON to XML using ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/vemonet/json2xml"}),"json2xml"),". This XML can be then converted to generic RDF."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"docker run -it -v $(pwd)/workspace/input:data vemonet/json2xml:latest -i /data/test.json \n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Shared on your machine at ",Object(n.b)("inlineCode",{parentName:"p"},"/data/d2s-workspace"))),Object(n.b)("hr",null),Object(n.b)("h3",{id:"pyshex"},"PyShEx"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/hsolbrig/PyShEx"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/hsolbrig/PyShEx?label=GitHub&style=social",alt:null})))),Object(n.b)("p",null,"Validate RDF from a SPARQL endpoint against a ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://shex.io/"}),"ShEx")," file."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"git clone https://github.com/hsolbrig/PyShEx.git\ndocker build -t pyshex ./PyShEx/docker\ndocker run --rm -it pyshex -gn '' -ss -ut -pr \\\n    -sq 'select ?item where{?item a <http://w3id.org/biolink/vocab/Gene>} LIMIT 1' \\\n    https://graphdb.dumontierlab.com/repositories/ncats-red-kg \\\n    https://github.com/biolink/biolink-model/raw/master/shex/biolink-modelnc.shex\n")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"rdf2hdt"},"rdf2hdt"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/rdfhdt/hdt-docker"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/rdfhdt/hdt-cpp?label=GitHub&style=social",alt:"GitHub"})))),Object(n.b)("p",null,"Convert RDF to ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://www.rdfhdt.org/"}),"HDT")," files. ",Object(n.b)("em",{parentName:"p"},"Header, Dictionary, Triples")," is a binary serialization format for RDF  that keeps big datasets compressed while maintaining search and browse operations without prior decompression."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"docker run -it --rm -v $(pwd)/workspace:/data \\\n  rdfhdt/hdt-cpp rdf2hdt /data/input.nt /data/output.hdt\n")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"jena-riot-validate-rdf"},"Jena riot validate RDF"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/stain/jena-docker"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/stain/jena-docker?label=GitHub&style=social",alt:"GitHub"})))),Object(n.b)("p",null,"Validate RDF or convert RDF to RDF using Apache Jena riot tool. See ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://hub.docker.com/r/stain/jena"}),"Jena on DockerHub"),"."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"docker run --volume $(pwd)/workspace:/rdf stain/jena:3.14.0 riot --validate input.ttl\n")),Object(n.b)("ul",null,Object(n.b)("li",{parentName:"ul"},"Convert RDF to RDF")),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"docker run --volume $(pwd)/workspace:/rdf stain/jena:3.14.0 riot --output=NQUADS input.ttl > output.nq\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"Jena does not allow to provide a output file, it uses standard output.")),Object(n.b)("p",null,"Use as ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/marketplace/actions/validate-rdf-with-jena"}),"GitHub Action"),":"),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-yaml"}),"- uses: vemonet/jena-riot-action@v3.14\n  with:\n    input: my_file.ttl\n")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"raptor-rdf2rdf"},"Raptor rdf2rdf"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"http://librdf.org/raptor/rapper.html"}),"Raptor")," is a small and efficient Bash tool to convert from a RDF format to another (nq, nt, ttl, rdf/xml). It can help fix triple normalization and encoding issues."),Object(n.b)("p",null,"JSON-LD not available, available format: "),Object(n.b)("ul",null,Object(n.b)("li",{parentName:"ul"},Object(n.b)("inlineCode",{parentName:"li"},"ntriples")),Object(n.b)("li",{parentName:"ul"},Object(n.b)("inlineCode",{parentName:"li"},"turtle")),Object(n.b)("li",{parentName:"ul"},Object(n.b)("inlineCode",{parentName:"li"},"nquads")),Object(n.b)("li",{parentName:"ul"},Object(n.b)("inlineCode",{parentName:"li"},"rdfxml"))),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"docker run -it --rm -v $(pwd)/workspace:/data \\\n  umids/raptor-rdf2rdf -i ntriples -o rdfxml /data/kg.nt > /data/kg.xml\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"See ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/pheyvaer/raptor-docker"}),"GitHub repository")," for Docker build.")),Object(n.b)("h3",{id:"rdf2neo"},"rdf2neo"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/Rothamsted/rdf2neo"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/Rothamsted/rdf2neo?label=GitHub&style=social",alt:"GitHub"})))),Object(n.b)("p",null,"Convert RDF data to a neo4j property graph by mapping the RDF to Cypher queries using ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/Rothamsted/rdf2neo"}),"Rothamsted/rdf2neo"),"."),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"To be developed.")),Object(n.b)("hr",null),Object(n.b)("h3",{id:"d2s-bash-exec"},"d2s-bash-exec"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/d2s-bash-exec"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/MaastrichtU-IDS/d2s-bash-exec?label=GitHub&style=social",alt:null})))),Object(n.b)("p",null,"Simple container to execute Bash scripts from URL (e.g. hosted on GitHub). Mainly used to download datasets. See ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/MaastrichtU-IDS/d2s-download/blob/master/datasets/TEMPLATE/download.sh"}),"download script example"),"."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"docker run -it --rm -v $(pwd)/workspace/input:/data umids/d2s-bash-exec:latest https://raw.githubusercontent.com/MaastrichtU-IDS/d2s-project-template/master/datasets/stitch/download/download-stitch.sh\n")),Object(n.b)("blockquote",null,Object(n.b)("p",{parentName:"blockquote"},"See on ",Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://hub.docker.com/r/umids/d2s-bash-exec"}),"DockerHub"),".")),Object(n.b)("hr",null),Object(n.b)("h2",{id:"additional-services"},"Additional services"),Object(n.b)("h3",{id:"bridgedb"},"BridgeDb"),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/bridgedb/BridgeDb"}),Object(n.b)("img",Object(r.a)({parentName:"a"},{src:"https://img.shields.io/github/stars/bridgedb/BridgeDb?label=GitHub&style=social",alt:null})))),Object(n.b)("p",null,Object(n.b)("a",Object(r.a)({parentName:"p"},{href:"https://www.bridgedb.org/"}),"BridgeDb")," links URI identifiers from various datasets (Uniprot, PubMed)."),Object(n.b)("pre",null,Object(n.b)("code",Object(r.a)({parentName:"pre"},{className:"language-shell"}),"docker run -p 8183:8183 bigcatum/bridgedb\n")),Object(n.b)("h3",{id:"rdf-tools-to-try"},"RDF tools to try"),Object(n.b)("p",null,"Interesting tools to work with RDF that have not yet been tried."),Object(n.b)("ul",null,Object(n.b)("li",{parentName:"ul"},Object(n.b)("a",Object(r.a)({parentName:"li"},{href:"https://astrea.linkeddata.es/"}),"Astrea"),": generate SHACL Shape from ontology"),Object(n.b)("li",{parentName:"ul"},Object(n.b)("a",Object(r.a)({parentName:"li"},{href:"https://github.com/AtomGraph/JSON2RDF"}),"AtomGraph json2rdf"),": convert JSON to generic RDF based on its structure."),Object(n.b)("li",{parentName:"ul"},"List of RDF tools published by the Semantic Technologie Institute (STI) Innsbruck: ",Object(n.b)("a",Object(r.a)({parentName:"li"},{href:"https://stiinnsbruck.github.io/kgs/"}),"https://stiinnsbruck.github.io/kgs/"))))}i.isMDXComponent=!0}}]);