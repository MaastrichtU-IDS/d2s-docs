---
id: d2s-run
title: Run CWL workflows
---

![CWL](/img/CWL_logo.png)

## Download files to convert

Files to process (e.g. CSV, XML) needs to be downloaded before running the workflow.

Example for `drugbank`:

```shell
d2s download drugbank
```

> Downloaded files goes to `workspace/input/drugbank`.

## Convert XML

Use [xml2rdf](https://github.com/MaastrichtU-IDS/xml2rdf) to generate RDF based on the XML structure:

```shell
d2s run workflow-xml.cwl drugbank
```

> Example converting [DrugBank](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/datasets/drugbank) (drug associations) to the [BioLink](https://biolink.github.io/biolink-model/docs/) model.

> Output goes to `workspace/output`

---

## Convert CSV/TSV

Use [AutoR2RML](https://github.com/amalic/autor2rml) and Apache Drill to generate R2RML mapping based on input data structure:

```shell
d2s download cohd
d2s run workflow-csv.cwl cohd
```

> Example converting [cohd](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/datasets/cohd) (clinical concepts co-occurence) to the [BioLink](https://biolink.github.io/biolink-model/docs/) model.

### Convert CSV/TSV and split a property

> Not tested at the moment. Might need fix.

Convert CSV/TSV and split statements (e.g. `?s ?p "value1,value2,value3"` would be splitted in 3 statements):

```shell
d2s download eggnog
d2s run workflow-csv-split.cwl eggnog
```

> Example converting the [EggNOG](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/datasets/drugbank) dataset to the [BioLink](https://biolink.github.io/biolink-model/docs/) model.

---

## Run in the background

```shell
nohup d2s run workflow-xml.cwl drugbank &
```

> Write terminal output to `nohup.out`.

---

## Generate mappings

When you start converting a new dataset `d2s` can help you generate mapping files based on the input data structure. You can then edit the generated SPARQL queries to adapt them to your target model.

```shell
d2s run workflow-csv.cwl cohd --get-mappings
```

> `--get-mappings`  causes the template mapping files generated by `d2s` to be copied to `/datasets/$dataset_id/mappings`

---

## Workflow details

* By default we are using `workspace/` as working directory when running workflows and starting services.

* You need to put the SPARQL mapping queries in `/mappings/$dataset_name` and provide those parameters:
  * `--outdir`: final output directory for files outputted by the workflow
    * e.g. `workspace/output/$dataset_id`.
  * `--tmp-outdir-prefix`: directory for output files (tmp) of each step 
    * e.g. `workspace/output/tmp-outdir`
  * `--tmpdir-prefix`: directory used to pass inputs of each step
    * e.g. `workspace/output/tmp-outdir/tmp-`
  * `--custom-net`: docker network used by all containers run in this workflow
  * The `.cwl` [workflow file](https://github.com/MaastrichtU-IDS/d2s-transform-template/blob/master/support/cwl/workflow-xml.cwl)
    * e.g. `d2s-cwl-workflows/workflows/workflow-xml.cwl`
  * The `.yml` [configuration file](https://github.com/MaastrichtU-IDS/d2s-transform-template/blob/master/support/example-config/config-transform-xml-drugbank.yml) with all parameters required to run the workflow
    * e.g. `support/example-config/config-transform-xml-drugbank.yml`
* 3 types of workflows can be run depending on the input data and the tasks executed:

  * XML
  * CSV/TSV
  * CSV/TSV with split of a statement
