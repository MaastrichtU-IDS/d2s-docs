---
id: d2s-run
title: Run CWL workflows
---

![CWL](/img/CWL_logo.png)

[CWL workflows](https://www.commonwl.org/) can be run to perform various task such as executing transformation pipeline to build a RDF Knowledge Graph.

## Download files to convert

Files to process (e.g. CSV, XML) needs to be downloaded before running a workflow 📥

```shell
d2s download <dataset_id>
```

> Download script defined in [datasets/dataset_id/download/download.sh](https://github.com/MaastrichtU-IDS/d2s-transform-template/blob/master/datasets/cohd/download/download.sh).

> Downloaded files goes to `workspace/input/dataset_id`.

## Run a CWL workflow

Run a CWL workflow defined in [d2s-cwl-workflows/workflows](https://github.com/MaastrichtU-IDS/d2s-cwl-workflows/tree/master/workflows) on a specific dataset:

```shell
d2s run <workflow_filename>.cwl <dataset_id>
```

> Output goes to `workspace/output`

### Convert CSV/TSV

Use [AutoR2RML](https://github.com/amalic/autor2rml) and Apache Drill to generate R2RML mapping based on input data structure. 

We provide an example converting a sample of [COHD](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/datasets/cohd) (clinical concepts co-occurences from FDA reports) to the [BioLink](https://biolink.github.io/biolink-model/docs/) model:

```shell
d2s download cohd
d2s run csv-virtuoso.cwl cohd
```

By default the workflow runs detached from your terminal, so you can close the Windows or leave the SSH sessions.

> You might face issues when processing large CSV or TSV file, see [this documentation](https://d2s.semanticscience.org/docs/guide-preprocessing#split-big-files) to deal with big files.

---

### With property split

> Not tested at the moment. Might need fix.

Convert CSV/TSV and split statements (e.g. `?s ?p "value1,value2,value3"` would be splitted in 3 statements). 

We provide a example converting a sample of the [EggNOG](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/datasets/drugbank) dataset to the [BioLink](https://biolink.github.io/biolink-model/docs/) model:

```shell
d2s download eggnog
d2s run split-csv-virtuoso.cwl eggnog
```

---

### Convert XML

Use [xml2rdf](https://github.com/MaastrichtU-IDS/xml2rdf) to generate RDF based on the XML structure. 

We provide a example converting a sample of [DrugBank 💊️](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/datasets/drugbank) (drug associations) to the [BioLink](https://biolink.github.io/biolink-model/docs/) model.

```shell
d2s download drugbank
d2s run xml-virtuoso.cwl drugbank
```

> Output goes to `workspace/output`

---

## Check the workflows logs

The workflow logs are stored in `workspace/workflow-history`.

### Watch a running workflow

You can watch the logs of a running workflow 👀

```shell
d2s watch csv-virtuoso.cwl-cohd-20200215-100352.txt
```

### Display workflow logs

Display the complete logs of any workflow previously run 📋

```shell
d2s log csv-virtuoso.cwl-cohd-20200215-091342.txt
```

---

## Run attached to the terminal

```shell
d2s run csv-virtuoso.cwl cohd --watch
```

> ⚠️ The logs will not be stored in `workspace/workflow-history`.

---

## Generate mappings

When you start converting a new dataset `d2s` can help you generate mapping files based on the input data structure. You can then edit the generated SPARQL queries to adapt them to your target model.

```shell
d2s run csv-virtuoso.cwl cohd --get-mappings
```

> `--get-mappings`  causes the template mapping files generated by `d2s` to be copied to `/datasets/$dataset_id/mappings`

---

## Workflow details

* We are using `workspace/` as working directory when running workflows and starting services.

* You need to put the SPARQL mapping queries in `/mappings/$dataset_name` and provide those parameters:
  * `--outdir`: final output directory for files outputted by the workflow
    * e.g. `workspace/output/$dataset_id`.
  * `--tmp-outdir-prefix`: directory for output files (tmp) of each step 
    * e.g. `workspace/output/tmp-outdir`
  * `--tmpdir-prefix`: directory used to pass inputs of each step
    * e.g. `workspace/output/tmp-outdir/tmp-`
  * `--custom-net`: docker network used by all containers run in this workflow
  * The `.cwl` [workflow file](https://github.com/MaastrichtU-IDS/d2s-transform-template/blob/master/support/cwl/xml-virtuoso.cwl)
    * e.g. `d2s-cwl-workflows/workflows/xml-virtuoso.cwl`
  * The `.yml` [configuration file](https://github.com/MaastrichtU-IDS/d2s-transform-template/blob/master/support/example-config/config-transform-xml-drugbank.yml) with all parameters required to run the workflow
    * e.g. `support/example-config/config-transform-xml-drugbank.yml`
* 3 types of workflows can be run depending on the input data and the tasks executed:

  * XML
  * CSV/TSV
  * CSV/TSV with split of a statement
