---
id: d2s-new-dataset
title: Add a new dataset
---

In this documentation I will use [d2s-transform-template](https://github.com/MaastrichtU-IDS/d2s-transform-template) as example, but you are encouraged to create a new Git repository [using the template](https://github.com/MaastrichtU-IDS/d2s-transform-template/generate).

## Generate the new dataset

The files required to transform the dataset will be generated in `datasets/$dataset_id`

```shell
d2s generate dataset
```

> You will be asked some informations about the dataset to create.

The dataset mappings, metadata and download files are created in the `dataset/$dataset_id` folder.

The dataset folder is generated based on [this template folder](https://github.com/MaastrichtU-IDS/d2s-core/tree/master/support/template/dataset). Example mapping files are provided for DrugBank XML data and Columbia Open Health clinical Data TSV data.

> [Let us know](/help) if those examples are helpful, or if they would need to be more explicit.

### Describe the dataset metadata

You are encouraged to improve the metadata description of your dataset by editing the 2 metadata files generated in `datasets/$dataset_id/metadata`.

A dozen of metadata needs to be defined through SPARQL query for the summary of the dataset, and then each distribution.

* SPARQL insert dataset [summary metadata](https://github.com/MaastrichtU-IDS/d2s-core/blob/master/support/template/dataset/metadata/metadata-template-0-summary.rq) (once by dataset).
* SPARQL insert dataset [distribution metadata](https://github.com/MaastrichtU-IDS/d2s-core/blob/master/support/template/dataset/metadata/metadata-template-1.rq) (for each new version).

> Change the URIs between `<>` and strings between `""`.

> We recommend using `Stardog RDF Grammars` extension in Visual Studio Code to edit SPARQL queries (`.rq` files).

### Add files to download

You can define the bash commands to download your dataset in `datasets/$dataset_id/download/download.sh`.

The files will be downloaded in `workspace/input/$dataset_id`.

A [template](https://github.com/MaastrichtU-IDS/d2s-core/blob/master/support/template/dataset/download/download_examples.sh) is provided with examples to download, unzip or add column labels provided.

> `d2s` extract data from csv/tsv files based on their column label. If your tabular doesn't have column you can add them at the end of the [download.sh](https://github.com/MaastrichtU-IDS/d2s-core/blob/master/support/template/dataset/download/download_examples.sh) file by using the `sed` command.

---

## Generate mappings

When you start converting a new dataset `d2s` can help you generating mapping files based on the input data structure. You can then edit the generated SPARQL queries to adapt them to your target model.

```shell
d2s run csv-virtuoso.cwl cohd --get-mappings
```

> `--get-mappings`  causes the mapping queries based on the input data structure generated by `d2s` to be copied to `/datasets/$dataset_id/mappings`

You can use those mappings as starting point to map the input data to your target model.

> Note: nested XML files can generate a lot of mapping files.

---

## SPARQL queries in details

[![SPARQL](/img/sparql_logo.png)](https://www.w3.org/TR/sparql11-overview/)

We use [SPARQL](https://www.w3.org/TR/sparql11-query/) to:

* Insert metadata about the dataset in the triplestore.
* Map the generic RDF, generated from your input data structure, to a target RDF and insert the refined RDF in the triplestore.

---

### Define the dataset metadata

Define the dataset [**HCLS descriptive metadata**](https://www.w3.org/TR/hcls-dataset/), you can find example of metadata for [DrugBank](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/datasets/drugbank/metadata).

Each dataset has 2 levels of metadata:
* The [summary metadata](https://github.com/MaastrichtU-IDS/d2s-transform-template/blob/master/datasets/drugbank/metadata/metadata-drugbank-0-summary.rq) need to be defined once for each dataset *(~10 fields to fill)*
* The [distribution metadata](https://github.com/MaastrichtU-IDS/d2s-transform-template/blob/master/datasets/drugbank/metadata/metadata-drugbank-1.rq) need to be defined for each new version *(~6 fields to fill)*


> Some distribution metadata is retrieved from the summary

> Most metadata fields don't need changes between versions

---

### Define mappings to target model

You can find example of SPARQL mapping queries for:

* **XML** files
  * [DrugBank](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/datasets/drugbank/mappings)
* **CSV/TSV** files
  * [COHD clinical data](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/datasets/cohd/mappings)
  * [Stitch](https://github.com/MaastrichtU-IDS/d2s-transform-template/blob/master/datasets/stitch/mappings/insert-stitch.rq)
  * [EggNOG](https://github.com/MaastrichtU-IDS/d2s-transform-template/blob/master/datasets/eggnog/mappings/insert-eggnog.rq)

> Defining the mappings is the hardest and most cumbersome part of data integration. We are working actively on making it easier, by working on mapping automation and graphical user interfaces.

The mapping definition is **straightforward for flat data format** such as CSV, TSV or relational databases. But **nested data representation** such as XML or JSON require more **complex mappings**.

If you are mapping a dataset for the first time we advice you to run [AutoR2RML](https://github.com/MaastrichtU-IDS/AutoR2RML) or [xml2rdf](https://github.com/MaastrichtU-IDS/xml2rdf) on the data to generate bootstrap SPARQL queries

* [AutoR2RML](https://github.com/MaastrichtU-IDS/AutoR2RML) automatically generates a SPARQL query extracting all columns value for each row. 
  * You just need to generate proper URIs using `BIND`
  * And write the statements corresponding to the target representation


> [PharmGKB](https://github.com/MaastrichtU-IDS/d2s-transform-template/blob/master/mapping/pharmgkb/transform/1/insert-pharmgkb.rq) is a good example of complex TSV file.

* [xml2rdf](https://github.com/MaastrichtU-IDS/xml2rdf) generates a SPARQL mapping file for each array it detects
  * Mapping generation for XML is still experimental as it is complex to detect which fields should be mapped.
  * Be careful when iterating on multiple different child arrays for a parent node in your SPARQL query. It can blow up the processing time. 

    * Always split your queries to never iterate over more than one array for a parent node.
    * E.g. if `drug:001` from a XML file has multiple `publications` and multiple `synonyms` nodes in its child, then it is preferable to get them in 2 different queries. Retrieving the 2 arrays in a single query would results in the returned row count be a cartesian product of the 2 arrays, which grows exponentially with the size of each array.
    * Final semantic results are the same, but the performance of the transformation is highly impacted.

> [DrugBank](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/mapping/drugbank/transform/1) is a good example of multiple mappings files to handle arrays.

---

### Execute the mappings

To perform the transformation, the SPARQL mapping queries is executed using the [d2s-sparql-operations](https://github.com/MaastrichtU-IDS/d2s-sparql-operations) module. 

This tool uses the [rdf4j](https://rdf4j.eclipse.org/) framework to execute multiple SPARQL queries files, marked by the `.rq` extension, from a same repository on a SPARQL endpoint.

The SPARQL query files to execute can be provided via:
* A [URL pointing to a directory](https://github.com/MaastrichtU-IDS/d2s-transform-template/tree/master/mapping/drugbank/transform/1) containing the `.rq` files in a GitHub repository.
* The local filesystem repository (sharing volume).


[![RDF4J](/img/RDF4J_logo.png)](https://rdf4j.eclipse.org/)